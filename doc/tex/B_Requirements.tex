\apendice{Requirements}

\section{Introduction}

\nonzeroparskip This section lists the general objectives and requirements identified during the initial planning of the project and on whose fulfillment the development of the project has focused.

\section{General objectives}

\nonzeroparskip The requirements through which the use case was built were the following:
\begin{itemize}
	\item Ability to obtain data in real time.
	\item Combine at least two different data sources.
	\item Potential to scale in both technology and data volume.
	\item Involve various technologies from the world of Big Data.
	\item Mostly open source tools.
\end{itemize}

\section{Catalog of requirements}

\nonzeroparskip The functional requirements (FR) that the project had to meet were:
\begin{itemize}
	\item \textbf{FR1}. The data must be obtained from the Twitter hashtag \texttt{\textit{\#NowPlaying}} every 30 minutes, taking care of API rate limits.
	\item \textbf{FR2}. There must be at least two different visualizations and one of them must provide the ability to view all of the stored data.
	\item \textbf{FR3}. At least one of the visualizations must show last songs name, artist and audio features.
	\item \textbf{FR4}. At least one of the visualization must have a link to the source tweet.
	\item \textbf{FR5}. At least one of the visualization must have the ability to compare different metrics.
	\item \textbf{FR6}. At least one of the visualization must combine two different types of visualization.
	\item \textbf{FR7}. Both visualizations must provide sorting capabilities.
	\item \textbf{FR8}. Both visualizations must be responsive to different screen sizes.
\end{itemize}

\nonzeroparskip The technical requirements(TR) that the project had to meet were:
\begin{itemize}
	\item \textbf{TR1}. The development must have the ability to be deployed in different environments with minimum effort.
	\item \textbf{TR2}. The data flow must be automated, with the entire process orchestrated by a single tool.
	\item \textbf{TR3}. The execution of the ETL process must be done with a tool that can scale and run in distributed environments.
	\item \textbf{TR4}. The data warehouse must have the ability to escalate in terms of a Big Data problem.
	\item \textbf{TR5}. The back and front end must be designed with widely recognized tools.
\end{itemize}

\section{Requirements specification}
