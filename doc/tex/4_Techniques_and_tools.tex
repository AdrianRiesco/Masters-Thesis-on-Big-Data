\capitulo{4}{Techniques and tools}

\nonzeroparskip In this section are presented the methodological techniques and development tools used to carry out the project.

\section{GitHub}

\nonzeroparskip GitHub~\footnote{\url{https://github.com/}} is a collaborative development platform created in 2008 and based on the Git version control system. Github has a freemium model and provides the ability to host both public and private projects, focusing primarily on code development~\cite{wikipedia_github}.

\nonzeroparskip GitHub is the repository in which the project has been managed and hosted, and Git is the version control through which the commits have been made from the local environment. For the agile methodology, the Milestones have been used as sprints and the Issues as the tasks to be carried out in each of them.

\section{Postman}

\nonzeroparskip Postman~\footnote{\url{https://www.postman.com/}} is a tool that allows the user to build and use APIs in a simple way. Some of its characteristics are the API repository (easier storage, cataloging and collaboration), the availability of tools to help in the API design, testing and documentation, the workspaces to organize the work, and built-in integrations with tools such as GitHub, Azure DevOps, Jenkins, Splunk, Slack and Microsoft Teams. In addition, Postman is based on open source technologies, which provides the ability to be easily extended~\cite{postman}.

\section{Apache Airflow}

\nonzeroparskip Apache Airflow~\footnote{\url{https://airflow.apache.org/}} is a service orchestrator that allows you to plan, manage, and monitor workflows~\cite{airflow}. It was created in 2014 by Airbnb with the aim of handling the company's huge data flows, and published in 2015 under an open source license. In March 2016 the project joined the Apache Software Foundations incubator and was published as a top level project in 2019.

\nonzeroparskip Airflow is used to automate jobs by breaking them down into smaller tasks. For example, this project uses Airflow to automate the ETL process that consumes data from Twitter and Spotify, processes it, and serves it to the user. Among the main features of Airflow are scalability and ease of integration with other tools.

\nonzeroparskip The main element used by Airflow are the Directed Acyclic Graphs or DAGs, which are groups of tasks connected to each other through dependencies like the nodes of a graph. The word \textit{direct} indicates that the existing relationships in the graph must only have one direction (bidirectional relationships between nodes or tasks are not allowed), while the word \textit{acyclic} means that cycles cannot exist in the graph (nodes or tasks cannot be executed more than once). Tasks are defined by means of an operator and there is a very extensive library with operators that allow defining a wide variety of services such as BashOperator, to execute Bash commands, or SparkSubmitOperator, to submit a task to Spark. Regarding the programming language, Python is the one in which DAGs are developed.

\nonzeroparskip Airflow allows you to have control of the tasks executed through a record of their executions, the time, the current or final status and the generated logs. In addition, it allows certain parameters to be associated with each task, such as, for example, the maximum execution time allowed.

\section{Apache Spark}

\nonzeroparskip Apache Spark~\footnote{\url{https://spark.apache.org/}} is a multi-language engine that emerged in 2009 at the University of California used for data processing and machine learning designed for both simple single-node and distributed architectures~\cite{infoworld_spark}. Apache Spark supports the Python, Scala, SQL, Java and R programming languages and allows to design pipelines for large volumes of data for batch and streaming processing. Currently, Spark is one of the most widely used large-scale data processing frameworks.

\nonzeroparskip Key features of Apache Spark include its ability to scale, its speed, and the multitude of free resources made available by the large Apache community. In addition, Apache Spark has been adapted to the main cloud solutions, such as Databricks, Amazon Web Services, Google Cloud Platform and Microsoft Azure.

\nonzeroparskip The Apache Spark architecture is mainly composed of:
\begin{itemize}
	\item \textbf{Driver.} Turn code into tasks to distribute to worker nodes. This code goes on to form DAGs, which indicate the order of the tasks and the node in which they are going to be executed.
	\item \textbf{Executors.} They run on worker nodes and execute assigned tasks.
\end{itemize}

\nonzeroparskip Finally, one of the most characteristic elements of Spark is the Resilient Distributed Dataset or RDD. RDDs are abstractions that represent a collection of immutable objects that can be divided among the different nodes of a cluster and executed in a distributed way.

\section{Cassandra}

\nonzeroparskip Apache Cassandra~\footnote{\url{https://cassandra.apache.org/_/index.html}} is a widely used open source non-relational database that emerged in 2008 as a Google code open source project and in March 2010 as an Apache top level project. It is based on a system that acts as a mix between key-value and column-oriented and introduces Cassandra Query Language or CQL, an alternative query language to SQL with a similar syntax~\cite{cassandra,wikipedia_cassandra}.

\nonzeroparskip Among its main features are:
\begin{itemize}
	\item \textbf{Scalability}. Its performance increases linearly by adding new nodes, which can be added in real time without affecting system performance.
	\item \textbf{Fault tolerance}. Due to its distributed system architecture, data is automatically replicated across multiple nodes and enables replication and redundancy to be provided across multiple datacenters. Cassandra works with partitions, where each node owns a set of tokens whose ranges determine what data to send to each node within the cluster.
	\item \textbf{Decentralization}. All nodes in the cluster are assigned the same role, with no master node that can act as a single point of failure.
	\item \textbf{Consistency}. Considering the CAP theorem (Consistency-Availability-Partition tolerance), Cassandra is built to be AP, that is, to sacrifice consistency to ensure continuous operation without failures. Cassandra allows you to adjust this level of consistency by selecting the minimum number of nodes that must validate a read or write operation before it is considered successful.
\end{itemize}

\nonzeroparskip Cassandra was used in the project as the main database to store Twitter and Spotify data.

\section{Flask}

\nonzeroparskip Flask~\footnote{\url{https://flask.palletsprojects.com/en/2.1.x/}} is a Python-based open-source web framework created in 2004 and used to build web applications~\cite{flask}. It is considered a micro web framework because it does not lay on other tools or libraries to work, building a solid core and providing the capability to extend its operation. Flask uses Jinja as its template engine.

\nonzeroparskip During development, Flask v2.1.2 has been used to build the backend of the web application, gathering the data from the database and routing the user to the three existing views.

\section{Bootstrap}

\nonzeroparskip Bootstrap~\footnote{\url{https://getbootstrap.com/}} is an open-source CSS (Cascading Style Sheets) framework whose objective is to facilitate the design of responsive web interfaces~\cite{bootstrap}. Bootstrap bases its operation on a grid system with divisions of up to twelve columns, six responsive levels and a multitude of classes and configurations.

\nonzeroparskip During development, Bootstrap v5 has been used to organize the visual appearance of the three views of the web application and control the placement and responsiveness of its elements to screen size variations.

\section{Chart.js}

\nonzeroparskip Chart.js~\footnote{\url{https://www.chartjs.org/}} Chart.js is an open source Javascript library used to make charts using HTML code~\cite{w3schools_chartjs}. The use of this library is very simple, it has a large user community and, although it does not have a wide variety of graph types, they are enough to satisfy basic visualization needs.

\nonzeroparskip During development, a Chart.js v2.5.0 mixed graph with data in bar and line formats has been used to build the final visualizations.

\section{Datatables}

\nonzeroparskip Datatables~\footnote{\url{https://datatables.net/}} Datatables is an open source plugin for the jQuery javascript library that provides an easy and flexible way to design HTML-based data tables~\cite{datatables}. Among the features that can be added are the selection of the number of rows to display, pagination, multi-column sorting, search and customization of colors and formats.

\nonzeroparskip During development, Datatables v1.12.1 was used to create the final display in table format, complete with the ability to hide and show table columns.

\section{Docker}

\nonzeroparskip Docker~\footnote{\url{https://www.docker.com/}} is an open-source tool that emerged in 2013 that allows you to add an abstraction layer to the deployment of applications by automating them in a container from software~\cite{docker}. Through Docker, software development can be simplified and applications can be executed in different work environments more easily.

\nonzeroparskip The containers raised by Docker are associated with an image. To build an image in Docker, a file called Dockerfile with a specific syntax is used. Once built, the image will contain the Dockerfile along with the libraries and code specified, and any desired containers can be launched from it.

\nonzeroparskip Docker allows integration with tools such as Ansible and Jenkins, and with cloud providers such as Microsoft Azure, Google Cloud Platform and Amazon Web Services, among others.

\section{Docker Compose}

\nonzeroparskip Docker Compose~\footnote{\url{https://docs.docker.com/compose/}} is a solution that allows you to manage multiple Docker containers on a single host machine~\cite{docker_compose}.

\nonzeroparskip Docker Compose uses a yaml file to indicate the services you want to build along with the images each one should be based on. In this file you can indicate environment variables, dependencies, ports and even commands that must be launched at startup.

\nonzeroparskip While Docker Compose is the Docker container management solution on a single machine, Docker Swarm is the orchestration tool for managing containers on multi-machine distributed architectures.
