\capitulo{4}{Techniques and tools}

\nonzeroparskip In this section are presented the methodological techniques and development tools used to carry out the project.

\section{GitHub}

\nonzeroparskip GitHub is a collaborative development platform created in 2008 and based on the Git version control system. Github has a freemium model and provides the ability to host both public and private projects, focusing primarily on code development~\cite{wikipedia_github}.

\nonzeroparskip GitHub is the repository in which the project has been managed and hosted, and Git is the version control through which the commits have been made from the local environment.

\section{APIs}

\nonzeroparskip During this project there were used APIs from two different providers to gather the information: Twitter API and Spotify API.

\section{Postman}

\nonzeroparskip Postman is a tool that allows the user to build and use APIs in a simple way. Some of its characteristics are the API repository (easier storage, cataloging and collaboration), the availability of tools to help in the API design, testing and documentation, the workspaces to organize the work, and built-in integrations with tools such as GitHub, Azure DevOps, Jenkins, Splunk, Slack and Microsoft Teams. In addition, Postman is based on open source technologies, which provides the ability to be easily extended~\cite{postman}.

\section{Apache Airflow}

\nonzeroparskip Apache Airflow is a service orchestrator that allows you to plan, manage, and monitor workflows~\cite{airflow}. It was created in 2014 by Airbnb with the aim of handling the company's huge data flows, and published in 2015 under an open source license. In March 2016 the project joined the Apache Software Foundations incubator and was published as a top level project in 2019.

\nonzeroparskip Airflow is used to automate jobs by breaking them down into smaller tasks. For example, this project uses Airflow to automate the ETL process that consumes data from Twitter and Spotify, processes it, and serves it to the user. Among the main features of Airflow are scalability and ease of integration with other tools.

\nonzeroparskip The main element used by Airflow are the Directed Acyclic Graphs or DAGs, which are groups of tasks connected to each other through dependencies like the nodes of a graph. The word \textit{direct} indicates that the existing relationships in the graph must only have one direction (bidirectional relationships between nodes or tasks are not allowed), while the word \textit{acyclic} means that cycles cannot exist in the graph (nodes or tasks cannot be executed more than once). Tasks are defined by means of an operator and there is a very extensive library with operators that allow defining a wide variety of services such as BashOperator, to execute Bash commands, or SparkSubmitOperator, to submit a task to Spark. Regarding the programming language, Python is the one in which DAGs are developed.

\nonzeroparskip Airflow allows you to have control of the tasks executed through a record of their executions, the time, the current or final status and the generated logs. In addition, it allows certain parameters to be associated with each task, such as, for example, the maximum execution time allowed.

\section{Apache Spark}

\nonzeroparskip Apache Spark is...

\section{Cassandra}

\nonzeroparskip Apache Cassandra is a widely used open source non-relational database that emerged in 2008 as a Google code open source project and in March 2010 as an Apache top level project. It is based on a system that acts as a mix between key-value and column-oriented and introduces Cassandra Query Language or CQL, an alternative query language to SQL with a similar syntax~\cite{cassandra,wikipedia_cassandra}.

\nonzeroparskip Among its main features are:
\begin{itemize}
	\item \textbf{Scalability}. Its performance increases linearly by adding new nodes, which can be added in real time without affecting system performance.
	\item \textbf{Fault tolerance}. Due to its distributed system architecture, data is automatically replicated across multiple nodes and enables replication and redundancy to be provided across multiple datacenters. Cassandra works with partitions, where each node owns a set of tokens whose ranges determine what data to send to each node within the cluster.
	\item \textbf{Decentralization}. All nodes in the cluster are assigned the same role, with no master node that can act as a single point of failure.
	\item \textbf{Consistency}. Considering the CAP theorem (Consistency-Availability-Partition tolerance), Cassandra is built to be AP, that is, to sacrifice consistency to ensure continuous operation without failures. Cassandra allows you to adjust this level of consistency by selecting the minimum number of nodes that must validate a read or write operation before it is considered successful.
\end{itemize}

\nonzeroparskip Cassandra was used in the project as the main database to store Twitter and Spotify data.

\section{Flask}

\nonzeroparskip Flask is...

\section{Bootstrap}

\nonzeroparskip Bootstrap is...

\section{Docker}

\nonzeroparskip Docker is...

\section{Docker Compose}

\nonzeroparskip Docker Compose is...
